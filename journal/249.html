<html>
<head>
<title>One Small Voice: The Word</title>
<link rel="stylesheet" type="text/css" href="/stpeter.css">
<link rel="alternate" type="application/atom+xml" href="http://stpeter.im/atom.xml">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width">
<meta name="DC.Creator" content="Peter Saint-Andre">
<meta name="DC.Rights" content="https://creativecommons.org/publicdomain/zero/1.0/">
<meta name="DC.Title" content="The Word">
<meta name="DC.Date" content="2002-06-30">
</head>
<body>
<h2>The Word</h2>
<h3>by <a href="/">Peter Saint-Andre</a>
</h3>
<h3>2002-06-30</h3>
<p>I've started participating in a small philosophy-oriented discussion with some friends of mine. The first book we're reading is <a href="http://humwww.ucsc.edu/humbooks/LanguageThoughtLogic.html">Language, Thought, and Logic</a> by John M. Ellis. Here are some notes I posted to our discussion list about Chapter 2 of Ellis's book:</p>
<blockquote>
<p>In Chapter 2 of Logic, Thought, and Language, John Ellis delineates what he sees as three fundamental errors in the theory of language (15-16). These three wrong turns consist of the following assumptions:</p>
<ol>
<li>The purpose of language is communication.</li>
<li>Descriptive words are central to a theory of language because scientific explanation proceeds from simple cases to difficult cases.</li>
<li>Verbal categories group like things together.</li>
</ol>
<p>It appears that Ellis would oppose these three assumptions by making the following three claims:</p>
<ol>
<li>The purpose of language is first and foremost conceptualization.</li>
<li>Evaluative words are central to a theory of language because science must attack the hard cases head-on.</li>
<li>Verbal categories group <em>unlike</em> things together.</li>
</ol>
<p>In the paragraphs below I review each of these claims and contrast it with the assumption to which it is opposed.</p>
<p>Ellis draws a distinction between a code and language (16-18). Some theorists hold that a language is a code (specifically, a code of communication), but Ellis notes that the concept of a code presupposes the existence of information that is to be encoded. Far from encoding information that exists in some other form, a language is the way that human beings create or structure information; i.e., a language is the end result and expression of a long process of analyzing, evaluating, and organizing human experience, and thus of determining what will even count as information.</p>
<p>This is connected with his third claim, for the categories inherent in a language are the key way in which it determines what counts as information. For Ellis, such categories integrate and organize the infinite variation and diversity of experience into a more manageable number of concepts. The things or experiences that a concept treats as like are in fact distinct and unidentical; however, for the purpose of linguistic and conceptual economy a language groups such things into one "bucket" and treats them all the same.</p>
<p>Here we find a connection to Ellis's second claim: for he holds that, historically, human concepts did not first differentiate logically simple categories such as cat or square, but rather more complex categories such as food vs. poison (most of which have evaluative overtones -- food is good, poison is bad). Ellis argues that human artifacts (e.g., table) and scientific concepts (e.g., triangle) make poor fodder for linguistic theory, since they are too simple and have resulted relatively recently from processes of scientific or technological endeavor. By contrast, concepts like poison are both more complex and more ancient, having emerged in an almost evolutionary fashion to treat many unlike things (mushrooms, berries, leaves, etc.) as if they were the same, again for the purpose of evaluation (and survival) rather than pure description.</p>
<p>It strikes me that Ellis is making a few assumptions of his own here. One is that the simplicity of a concept can be directly correlated with the degree to which it isolates one kid of thing (e.g., cats or squares) rather than many things (e.g., things inimical to health). Yet there are, legitimately, many different kinds of dimensions along which things can be measured, and measuring along some of those dimensions (e.g., life vs. death in the case of food vs. poison) may result in a perfectly legitimate concept that isolates many different kinds of things (e.g, certain kinds of mushrooms and berries and leaves) from all others.</p>
<p>Another assumption made by Ellis seems to be that the most ancient human concepts were in the main evaluative rather than descriptive, and that purely descriptive concepts are an overlay of human intellectual progress (what we can call science in the broad sense). Yet there is no real evidence for this notion. It may well be that certain human evaluations started out as merely "good" vs. "bad" and that over time as human knowledge became more sophisticated these evaluations became more nuanced and more grounded in facts (e.g., "he is a good husband" morphed into "he is supportive, understanding, a good communicator, etc." with the growth of psychological knowledge). Perhaps I simply lack imagination, but I find it hard to see how purely "descriptive" concepts (man, woman, stone, dog, etc.) could not have been part of human language from the beginning, since it was absolutely necessary to conceptualize such things, given that they were central features of human experience.</p>
<p>Thus while I think that Ellis has cleared much of the underbrush within the theory of language, he has unfortunately left some of his own assumptions unquestioned. How damaging these assumptions are to his own positive theory remains to be seen.</p>
</blockquote>
<hr>
<p><a href="/">Peter Saint-Andre</a> &gt; <a href="/journal/">Journal</a></p>
</body>
</html>
