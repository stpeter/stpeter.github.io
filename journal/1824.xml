<journal>
<header><title>Opinion Machines</title><date>2023-09-29</date></header>
<entry>
<p>As I've striven over the last few years to hold fewer opinions, those who hold opinions about seemingly everything have become more noticeable to me. Whether it's the prospects for runaway inflation, the underlying causes for increasing loneliness in society, or the likely outcome of the upcoming elections in Ecuador, some bloggers and pundits are like opinion machines, able to crank out a position on anything at a moment's notice.</p>
<p>Interestingly, they have this in common with large language models (which some people call artificial intelligence, although I refuse to do so because think it begs the question). No matter what you ask ChatGPT and friends, you'll always get an opinion - never "I haven't studied that topic" or "that's not my concern" or "hell if I know" or, best of all, an intelligent question. Worse, in my experience LLMs tend to present you with a consensus opinion a.k.a. the received wisdom - which, if you ask me, isn't wisdom at all. Some folks believe that AI is going to take over the world in all sorts of creative and enterprising ways, but so far I find these systems quite boring. And if they <em>do</em> take over the world, the place might be awfully dull!</p>
<p>(<a href='https://philosopher.coach/2023/09/29/opinion-machines/'>Cross-posted</a> at <a href='https://philosopher.coach/'>philosopher.coach</a>.)</p>
<p><em>FOR FURTHER EXPLORATION</em></p>
<ul>
<li><a href='1664.html'>Holding Fewer Opinions (2021-04-06)</a></li>
</ul>
</entry>
</journal>
